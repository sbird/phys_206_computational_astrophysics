\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{latexsym,amsfonts,amssymb,amsthm,amsmath,graphicx}
\usepackage{hyperref}

% \setlength{\parindent}{0.5in}
\setlength{\oddsidemargin}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.8in}
\setlength{\topmargin}{0in}
\setlength{\headheight}{18pt}

\newcommand{\Lc}{$\mathcal{L}$}


\title{ASTR 206 Lecture Notes}
\author{Simeon Bird}
% \date{October 14, 2019}

\begin{document}

\maketitle

\section{Gravitational Simulations}

This section is about N-Body codes, or the problem of simulating gravitational interactions. An important difference from other types of physical simulations is that gravity is a non-local interaction, which significantly changes the types of simulation models that can be used. Note that there are two types of N-body code. One simulates structure formation, where an initially uniform density dark matter fluid in an expanding background is allowed to evolve under self-gravity. We are concerned with the other, which models the evolution of small clusters of stars or black holes.

The first N-body simulation was performed by Eric Holmberg in 1941. The forces were computed using O(N) effort by placing light bulbs in a room and computing accelerations using light fluxes onto a photon cell. The bulbs were then moved by hand.

In this problem:

\begin{enumerate}
 \item Each star/BH is a point particle.
 \item The force on each star is given by Newtonian gravity. For particle $j$ the force from other particles $i \neq j$ is:
\end{enumerate}
\begin{equation}
 a_j = \Sigma_i \frac{G M_i}{\left(r_i - r_j\right)^2}
\end{equation}

Why can we treat a star as a point particle? Because even in the densest cluster the distance between stars is usually much larger than the size of a star.

It is well known that a 2-body problem is solvable analytically, but the 3-body problem is not, except under very special conditions. It is furthermore chaotic: the final state depends sensitively on the initial positions and velocities. The N-body problem is also analytically intractable.

\subsection{Forces}

Let's first talk about fast ways to compute the forces. The obvious algorithm is something like:
\begin{verbatim}
 for j in particles:
    acc_j = 0
    for i in particles:
      if i != j:
        acc_j += G M_i / (r_i - r_j)^2
\end{verbatim}
but this is slow for large numbers of particles: for N particles this needs $N \times N$ operations and thus is said to be $O(N^2)$. Notice that this notation drops a constant prefactor: it could be $2 N^2$, $3 N^2$, or even $200 N^2$ operations, and it does not count how fast the operation is. Nevertheless, when $N \sim 10^{12}$, the cost is large.

\subsection{Timestepping}

We also need a discrete timestepping rule to move the system from time $t_i$ to time $t_{i+1} = t_i + \delta t$. This is a 6D system, 3 position variables ($x_i$) and 3 velocity variables ($v_i$), moving under Hamiltonian dynamics. A reasonable choice might seem to be:
\begin{align}
v_{i+1} &= v_i + a_i \delta t \\
x_{i+1} &= x_i + v_i \delta t
\label{eq:euler}
\end{align}
but this is in fact a terrible choice!

The gravitational system follows energy-conserving Hamiltonian dynamics. Because it is not robust to non-Hamiltonian perturbations, the discrete timestepping rule must also follow Hamiltonian dynamics, and so each step should preserve energy. Why does this choice not preserve energy?

More precisely, the thing that needs to be conserved is phase space volume. We can define a Hamiltonian in terms of canonical coordinates $p = m v$ and $x$:
\begin{equation}
 H = \frac{1}{2} \frac{p^2}{m} + \Phi (x)
\end{equation}
where $\Phi$ is the gravitational potential.
Then we have the dynamics:
\begin{align}
 \dot{x} &= \frac{\partial H}{\partial p} = \frac{p}{m}\\
 \dot{p} &= - \frac{\partial H}{\partial x} = - \frac{\partial \Phi}{\partial x}\\
\end{align}
Conserving phase space volume is written as $dp \times dx = 0$ and can be understood as ``close trajectories stay close''.

The Euler method from Eq.~\ref{eq:euler} can be written as a rule from (p,x) to (p', x'):
\begin{align}
\begin{pmatrix}
 p' \\
 x'
\end{pmatrix}
=
\begin{pmatrix}
1 & \frac{\delta t}{x} \frac{\partial H}{\partial x} \\
\delta t & 1 \\
\end{pmatrix}
.
\begin{pmatrix}
 p \\
 x
\end{pmatrix}
\end{align}
and $(p' - p)\times (x' - x)$ is not zero.

The fix to this is to use a \textbf{symplectic integrator}, notably the \textbf{leapfrog}. The idea is to split it into two sections, one part which evolves $dx$ and the other part which evolves $dp$. Since at any step either $dx$ or $dp$ is zero, the product is trivially zero.

Any Hamiltonian system ideally wants a symplectic integrator: the Hamiltonian Monte Carlo used in pymc also uses symplectic integration for steps.

We define two operators for the gravitational system, one which evolves the kinetic term (the ``kick'', $K$) and one which evolves the position term (the ``drift'', $D$). Each of these is individually phase space preserving, and we apply them in turn.

\begin{align}
 K(\delta t): v_i &\to v + a \delta t \\
 D(\delta t): x &\to x + v \delta t \\
\end{align}

The full timestep is kick-drift-kick, which splits the kick into two and is:
\begin{align}
K(\delta t/2) D(\delta t) F(x) K(\delta t/2) \\
\end{align}

At each step the position and velocities are at time:
\begin{align}
v(t) \to K \to v(t+\delta_t/2) \to &D \to v(t + \delta t/2) \to K \to v(t + \delta t) \\
x(t) \to K \to x(t) \to &D \to x(t + \delta t) \to K \to x(t + \delta t) \\
\end{align}
Note that F commutes with K.

When the drift is applied the velocity that is used is evaluated at $t + \delta t /2$. It would not be consistent to examine the energy of the system in the middle of the step, as the velocity and positions of the particles are at different times.

Choosing timestepping schemes which preserve energy is a good idea in computational astrophysics.

\subsection{Size of Timestep}

What should the timestep $\delta t$ be? We can choose a fixed number initially, but this is dangerous. To see why, remember that the particles move with constant velocity over a timestep. If acceleration is large compared to distance travelled during a timestep, this is inaccurate. The acceleration of a particle may change over the course of a simulation, so an initially `small' timestep may become `large' as the particles evolve. Directly using the ratio of instantaneous acceleration to distance travelled is practically difficult, because we don't know distance travelled before we work out the timestep.

We would like something that includes an acceleration estimate and has dimensions of time, which we can multiply by a dimensionless constant. It is tempting to mandate that the acceleration be small relative to the velocity:
\begin{equation}
 \delta t = \eta \frac{v}{a}
\end{equation}
where $\eta$ is a small dimensionless constant. However, this is a bad choice because it is not Galilean invariant: a frame boosted with respect to the particles will have a larger timestep. This could matter when, for example, we are simulating the merger of two star clusters.

Instead we can the ratio of the acceleration to the third derivative of the motion, or `jerk' $j$:
\begin{align}
 j &= \frac{d a}{dt}  = a' \\
 \delta t  &= \eta \frac{a}{j} = \eta \frac{a}{a'}
\end{align}
However this becomes a bad choice if $a$ is ever constant! It also has poor behaviour near the apocenter of a binary orbit. For this reason, we supplement the equation with functions of the second derivative of the acceleration, $a''$ (`snap'). \url{https://arxiv.org/pdf/2401.02849}.
\begin{align}
\delta t &= \eta \left( \left(\frac{a'}{a}\right)^2 + \frac{a''}{a}\right)^{-1/2}
\end{align}
To avoid situations where $a \to 0$ for a short time, and the timestep becomes infinite with loss of accuracy, we should also enforce that $\delta t$ can only increase by a factor of $2$ in a single timestep. This equation is still bad when $a'' = a' = 0$, but this much less likely!

Different particles will generically require different timesteps. To ensure the evolution of the system is correct, our simple code can compute $\delta t$ for all particles and use the minimum.

\subsection{Binary Formation}

A common feature of gravitational systems is the formation of binaries. One mechanism is three body interactions. Here one of the objects takes away the angular momentum of the system, leaving the other two bound.

If the binary is tight, the timestep needed to evolve it is small, and thus many more forces must be worked out. This is especially wasteful as the evolution of an isolated binary has an analytic solution. Some codes detect isolated binary systems and evolve them forward using the analytic solution. Many high performance codes allow the timesteps for each particle to be set individually, so that the binary does not slow down the whole simulation.\footnote{An issue that arises is how to model interactions between particles on different timesteps. For this see the Gadget-4 paper \url{https://arxiv.org/abs/2010.03567}.}

\section{Structure Formation}

For structure formation problems, things are similar, but instead of simulating point particles we are simulating an (almost) uniform density fluid. So the approximation that we made of point particles is no longer good. Why can we still use N-body techniques?

We can extensively use Birkhoff's theorem instead: the gravitation from any distribution of matter can be replaced by a point particle at the center of mass if the angular size is sufficiently small.

\section{Some Literature}
\begin{itemize}

\item Advanced N-body solver: \url{https://rebound.readthedocs.io/en/latest/}

\item Springel 2005, Gadget-2: \url{https://arxiv.org/abs/astro-ph/0505010}

\item Aarseth, Sverre ``Gravitational N-body Simulations'' \url{https://doi.org/10.1017/CBO9780511535246}

\item Binney and Tremaine ``Galactic Dynamics'' \url{https://doi.org/10.2307/j.ctvc778ff}

\item Timestepping \url{https://arxiv.org/pdf/2401.02849}
\end{itemize}

\end{document}
