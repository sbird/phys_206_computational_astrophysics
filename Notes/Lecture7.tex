\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, graphicx, caption, sidecap, enumitem, adjustbox}


% No automatic paragraph indent
\setlength\parindent{0pt}
% Change bullet points
\renewcommand{\labelitemiii}{$\circ$}


\begin{document}

\title{Physics 218 Lecture Notes}
\author{Mackenzie Vignoul}
\date{October 23, 2019}
\maketitle

\section{More on Hamiltonian Monte Carlo}

\textbf{Describe the No-U-Turn sampler}

Hamiltonian Monte Carlo (HMC) notably relies on the gradient of the likelihood. \\

\textbf{But how do you  compute the gradients?}
\begin{itemize}[itemsep=1pt]
\item We can do this numerically, but it introduces noise
\item We could do it analytically
\item The more common thing to do is use {\fontfamily{qcr}\selectfont autodiff}
\end{itemize}

\subsection{autodiff:}
Replace $\mathcal{L}(\text{{\fontfamily{qcr}\selectfont double}}\ x_i)$ with $\mathcal{L}(\text{{\fontfamily{qcr}\selectfont T}}\ x_i)$ where
\begin{equation*}
\text{{\fontfamily{qcr}\selectfont type T}} =
\begin{cases}
\text{{\fontfamily{qcr}\selectfont double}}\ x_i \\
\text{{\fontfamily{qcr}\selectfont double}}\ dx_i
\end{cases}
\end{equation*}
This works out the gradients \textit{while} computing the likelihood function and stores them.
\begin{itemize}[itemsep=1pt]
\renewcommand{\labelitemi}{$\Rightarrow$}
\item Note that this will not work as well if your likelihood has ``{\fontfamily{qcr}\selectfont if}'' statements
\end{itemize}

\vspace{5pt}

\textbf{How does it compute the gradient?}
\begin{itemize}[itemsep=1pt]
\item C++ : overloads the operator + and operator $\times$, and similar fundamental operations
\item All derivative computations are then just a combination and repetition of these
\end{itemize}

\vspace{1pt}

\subsection{HMC is very parallel}
\begin{itemize}[itemsep=1pt]
\item Depends only on the current position and gradient, not other points
\item Can have multiple chains sweeping out paths: they are independent
\end{itemize}

\vspace{11pt}

\textit{Unfortunately}, there is no standard, easy-to-use program.
\begin{itemize}[itemsep=1pt]
\item If you have a simple likelihood, can use Stan
\item A classic example: working out the amount of radon in basements in the US (you can't just directly average over houses)
\end{itemize}


\section{More on Probabilities}

\vspace{10pt}
\begin{large}
\[ P(M|D) = \frac{P(D|M)P(M)}{P(D)} \]
\end{large}

\vspace{8pt}

We can choose $P(D)$ such that $\sum P(M|D) = 1$ \textit{but} this can have its issues.

\subsection*{Example: Quasar Spectra}

We have a collection of spectra that look like: \\

\begin{tabular}[t]{cc}
\includegraphics[width=0.5\textwidth]{modelA} &
\includegraphics[width=0.5\textwidth]{modelB} \\
\begin{minipage}{0.45\textwidth}
We initially just consider models $A$ and $B$, but what happens when we get something that looks like model $C$ in our data? The computer says that model $C$ is just a very intense DLA in model $B$, which we know is not the case.
\end{minipage} & \raisebox{-0.5\height}{\includegraphics[width=0.5\textwidth]{modelC}}
\end{tabular}

\vspace{11pt}

\hspace{1em} $\Rightarrow$ Always look at your data with your eyes! Computers aren't good at common sense.

\vspace{11pt}

\textbf{What if} we instead said that $\sum P(M|D) = 0.99$ and introduced some third model $P(M_3|D)$ with $P(D|M_3) \sim 1$, $P(M_3) \sim 0.01$?
\begin{itemize}
\renewcommand{\labelitemi}{$\Rightarrow$}
\item Allow for some low probability that model $M_3$ shows up in our data but doesn't skew too much towards it, so the computer doesn't try to shove model $C$ into model $B$
\end{itemize}

\vspace{11pt}

\textbf{Moral of the story:} computers do what they're told, even if they clearly don't make sense. \\

$\ast$ Note that Bayesianism can't really rule out models or determine goodness of fit because you are essentially assuming from the get-go that your model is correct.


\end{document}
